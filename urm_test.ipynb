{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "T5f4w3Kq2X14"
   },
   "outputs": [],
   "source": [
    "#@title Import packages for plotting and creating graphics\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "from typing import Callable, NamedTuple, Optional, Union, List\n",
    "\n",
    "import mediapy as media\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# More legible printing from numpy.\n",
    "np.set_printoptions(precision=3, suppress=True, linewidth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ObF1UXrkb0Nd"
   },
   "outputs": [],
   "source": [
    "#@title Import MuJoCo, MJX, and Brax\n",
    "from datetime import datetime\n",
    "from etils import epath\n",
    "import functools\n",
    "from IPython.display import HTML\n",
    "from typing import Any, Dict, Sequence, Tuple, Union\n",
    "import os\n",
    "# from ml_collections import config_dict\n",
    "\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jp\n",
    "import numpy as np\n",
    "# from flax.training import orbax_utils\n",
    "# from flax import struct\n",
    "from matplotlib import pyplot as plt\n",
    "import mediapy as media\n",
    "# from orbax import checkpoint as ocp\n",
    "\n",
    "import mujoco\n",
    "from mujoco import mjx\n",
    "\n",
    "from brax import base\n",
    "from brax import envs\n",
    "from brax import math\n",
    "from brax.base import Base, Motion, Transform\n",
    "from brax.envs.base import Env, PipelineEnv, State\n",
    "from brax.mjx.base import State as MjxState\n",
    "from brax.training.agents.ppo import train as ppo\n",
    "from brax.training.agents.ppo import networks as ppo_networks\n",
    "from brax.io import html, mjcf, model\n",
    "from brax.base import System\n",
    "\n",
    "from copy import deepcopy as dc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAv6WUVUm78k"
   },
   "source": [
    "# TwoArm URM Env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mtGMYNLE3QJN"
   },
   "outputs": [],
   "source": [
    "#@title TwoArm Env\n",
    "\n",
    "\n",
    "class TwoArm(PipelineEnv):\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      forward_reward_weight=1.25,\n",
    "      ctrl_cost_weight=0.1,\n",
    "      healthy_reward=5.0,\n",
    "      terminate_when_unhealthy=True,\n",
    "      healthy_z_range=(1.0, 2.0),\n",
    "      reset_noise_scale=1e-2,\n",
    "      exclude_current_positions_from_observation=True,\n",
    "      **kwargs,\n",
    "  ):\n",
    "    d = 0.15\n",
    "    l1, l2 = 0.14, 0.14\n",
    "    bs = 0.15\n",
    "    q_limit = 2.5\n",
    "    savevideo =False\n",
    "\n",
    "    xml = '''\n",
    "    <mujoco>\n",
    "        <compiler angle=\"radian\" />\n",
    "        <option  timestep=\"0.001\" gravity=\"0 0 0\"/>\n",
    "        <default>\n",
    "          <geom solref=\"0.002 1\" contype=\"1\" conaffinity=\"1\" friction=\"0.3 0.005 0.0001\" />\n",
    "          <joint  armature=\"0.01\" range=\"-{5} {5}\"/>\n",
    "        </default>\n",
    "        <visual>\n",
    "          <map stiffness=\"10000\"/>\n",
    "          <global offheight=\"1280\" offwidth=\"1280\"/>\n",
    "        </visual>\n",
    "        <asset>\n",
    "          <texture type=\"skybox\" builtin=\"gradient\" rgb1=\".3 .5 .7\" rgb2=\"0 0 0\" width=\"32\" height=\"512\"/>\n",
    "          <texture name=\"body\" type=\"cube\" builtin=\"flat\" mark=\"cross\" width=\"128\" height=\"128\" rgb1=\"0.8 0.6 0.4\" rgb2=\"0.8 0.6 0.4\" markrgb=\"1 1 1\"/>\n",
    "          <material name=\"body\" texture=\"body\" texuniform=\"true\" rgba=\"0.8 0.6 .4 1\"/>\n",
    "          <texture name=\"grid\" type=\"2d\" builtin=\"checker\" width=\"512\" height=\"512\" rgb1=\".1 .2 .3\" rgb2=\".2 .3 .4\"/>\n",
    "          <material name=\"grid\" texture=\"grid\" texrepeat=\"4 4\" texuniform=\"false\" reflectance=\".0\"/>\n",
    "        </asset>\n",
    "\n",
    "        <worldbody>\n",
    "            <geom name=\"floor\" type=\"plane\" size=\".4 .4 0.01\" material=\"grid\" pos=\"0 0.2 -0.027\"/>\n",
    "            <camera name=\"top\" pos=\"0 0 1.0\" resolution=\"1280 1280\"/>\n",
    "            <body name=\"robot\">\n",
    "            <geom name=\"base\" type=\"capsule\" size=\"0.01\" fromto=\"-{3} -0.02 0 {3} -0.02 0\" />\n",
    "            <body name=\"R1\" pos=\"{0} 0 0.0\">\n",
    "                <geom type=\"capsule\" size=\"0.01\" fromto=\"0 0 0 0 {1} 0\" rgba=\"0 0 0 1\"/>\n",
    "                <joint name=\"R1j\" type=\"hinge\" pos=\"0 0 0\" axis=\"0 0 1\" />\n",
    "                <body name=\"R2\" pos=\"0 {1} 0\">\n",
    "                    <geom type=\"capsule\" size=\"0.01\" fromto=\"0 0 0 0 {2} 0\" />\n",
    "                    <joint name=\"R2j\" type=\"hinge\" pos=\"0 0 0\" axis=\"0 0 1\" />\n",
    "                </body>\n",
    "            </body>\n",
    "            <body name=\"L1\" pos=\"-{0} 0 0\">\n",
    "                <geom type=\"capsule\" size=\"0.01\" fromto=\"0 0 0 0 {1} 0\" rgba=\"0 0 0 1\"/>\n",
    "                <joint name=\"L1j\" type=\"hinge\" pos=\"0 0 0\" axis=\"0 0 1\" />\n",
    "                <body name=\"L2\" pos=\"0 {1} 0\">\n",
    "                    <geom type=\"capsule\" size=\"0.01\" fromto=\"0 0 0 0 {2} 0\"/>\n",
    "                    <joint name=\"L2j\" type=\"hinge\" pos=\"0 0 0\" axis=\"0 0 1\" />\n",
    "                </body>\n",
    "            </body>\n",
    "            </body>\n",
    "            <body name=\"obj\" pos=\"0 {4} 0.0\">\n",
    "              <joint type=\"slide\" axis=\"1 0 0\"/>\n",
    "              <joint type=\"slide\" axis=\"0 1 0\"/>\n",
    "              <joint type=\"hinge\" axis=\"0 0 1\"/>\n",
    "              <!-- <geom type=\"capsule\" size=\"{4} 0.025\" pos=\"0 0 0\"/> -->\n",
    "              <!-- <geom type=\"box\" size=\"{4} {4} 0.025\" pos=\"0 0 0\"/>  -->\n",
    "              <!-- <geom type=\"box\" size=\"{4} 0.01 0.025\" pos=\"0 0 0\"/> -->\n",
    "              <!-- <geom type=\"box\" size=\"0.01 {4} 0.025\" pos=\"0 0 0\"/> -->\n",
    "              <geom type=\"box\" size=\"0.02 0.02 0.025\" pos=\"0 0 0\"/>\n",
    "            </body>\n",
    "\n",
    "        </worldbody>\n",
    "\n",
    "        <actuator>\n",
    "          <general joint=\"R1j\"/>\n",
    "          <general joint=\"R2j\"/>\n",
    "          <general joint=\"L1j\"/>\n",
    "          <general joint=\"L2j\"/>\n",
    "          <damper joint=\"R1j\" ctrlrange=\"0 100000\" kv=\"1\"/>\n",
    "          <damper joint=\"R2j\" ctrlrange=\"0 100000\" kv=\"1\"/>\n",
    "          <damper joint=\"L1j\" ctrlrange=\"0 100000\" kv=\"1\"/>\n",
    "          <damper joint=\"L2j\" ctrlrange=\"0 100000\" kv=\"1\"/>\n",
    "        </actuator>\n",
    "\n",
    "    </mujoco>\n",
    "    '''.format(d, l1, l2, d - 0.02, bs/2, q_limit)\n",
    "    mj_model = mujoco.MjModel.from_xml_string(xml)\n",
    "    # mj_model.opt.solver = mujoco.mjtSolver.mjSOL_CG\n",
    "    # mj_model.opt.iterations = 6\n",
    "    # mj_model.opt.ls_iterations = 6\n",
    "\n",
    "    sys = mjcf.load_model(mj_model)\n",
    "\n",
    "    self.physics_steps_per_control_step = 1\n",
    "    kwargs['n_frames'] = kwargs.get(\n",
    "        'n_frames', 1)\n",
    "    kwargs['backend'] = 'mjx'\n",
    "\n",
    "    super().__init__(sys, **kwargs)\n",
    "\n",
    "    self.e_list = jp.zeros((16, 4))\n",
    "    ct = 0\n",
    "    for i in range(2):\n",
    "      for j in range(2):\n",
    "        for k in range(2):\n",
    "          for l in range(2):\n",
    "            self.e_list = self.e_list.at[ct].set( jp.array([ (-1.0)**(i), (-1.0)**(j), (-1.0)**(k), (-1.0)**(l)  ]))\n",
    "            ct +=1\n",
    "    self.q_limit = q_limit\n",
    "\n",
    "    self._forward_reward_weight = forward_reward_weight\n",
    "    self._ctrl_cost_weight = ctrl_cost_weight\n",
    "    self._healthy_reward = healthy_reward\n",
    "    self._terminate_when_unhealthy = terminate_when_unhealthy\n",
    "    self._healthy_z_range = healthy_z_range\n",
    "    self._reset_noise_scale = reset_noise_scale\n",
    "    self._exclude_current_positions_from_observation = (\n",
    "        exclude_current_positions_from_observation\n",
    "    )\n",
    "  \n",
    "  def transmission(self, d, w, e, f):\n",
    "    v = d.qvel[0:4]\n",
    "    ctrl = jp.zeros(self.sys.nu)\n",
    "    # ctrl.at[:4] = e * f\n",
    "    # ctrl.at[4:8] = jp.abs(v) * w\n",
    "    # return ctrl\n",
    "    return jp.concatenate([e*f, jp.abs(v) * w])\n",
    "  \n",
    "  # def controller(self, d, e_idx, q_target):\n",
    "  def controller(self, d, action):\n",
    "    idx = jp.argmax(action)\n",
    "    e = self.e_list[idx].squeeze()\n",
    "\n",
    "    q = d.qpos[0:4]\n",
    "    v = d.qvel[0:4]\n",
    "    kp = 10.0\n",
    "\n",
    "    f = kp* (jp.dot(e,(e * self.q_limit  - q - 2 * np.sqrt([0.01/kp]) * v)))\n",
    "    w = 0.1\n",
    "    return w, e, f\n",
    "\n",
    "  def reset(self, rng: jp.ndarray) -> State:\n",
    "    \"\"\"Resets the environment to an initial state.\"\"\"\n",
    "    rng, rng1, rng2 = jax.random.split(rng, 3)\n",
    "\n",
    "    low, hi = -self._reset_noise_scale, self._reset_noise_scale\n",
    "    qpos = self.sys.qpos0 + jax.random.uniform(\n",
    "        rng1, (self.sys.nq,), minval=low, maxval=hi\n",
    "    )\n",
    "    qvel = jax.random.uniform(\n",
    "        rng2, (self.sys.nv,), minval=low, maxval=hi\n",
    "    )\n",
    "\n",
    "    data = self.pipeline_init(qpos, qvel)\n",
    "\n",
    "    obs = self._get_obs(data, jp.zeros(self.sys.nu))\n",
    "    reward, done, zero = jp.zeros(3)\n",
    "    metrics = {\n",
    "        'forward_reward': zero,\n",
    "        'reward_linvel': zero,\n",
    "        'reward_quadctrl': zero,\n",
    "        'reward_alive': zero,\n",
    "        'x_position': zero,\n",
    "        'y_position': zero,\n",
    "        'distance_from_origin': zero,\n",
    "        'x_velocity': zero,\n",
    "        'y_velocity': zero,\n",
    "    }\n",
    "    return State(data, obs, reward, done, metrics)\n",
    "\n",
    "  @property\n",
    "  def action_size(self) -> int:\n",
    "    return 16\n",
    "\n",
    "  def step(self, state: State, action: jp.ndarray) -> State:\n",
    "    \"\"\"Runs one timestep of the environment's dynamics.\"\"\"\n",
    "    data0 = state.pipeline_state\n",
    "    w, e, f = self.controller(data0, action)\n",
    "    ctrl = self.transmission(data0, w, e, f)\n",
    "    data = self.pipeline_step(data0, ctrl)\n",
    "\n",
    "    com_before = data0.subtree_com[1]\n",
    "    com_after = data.subtree_com[1]\n",
    "    velocity = (com_after - com_before) / self.dt\n",
    "    forward_reward = self._forward_reward_weight * velocity[0]\n",
    "\n",
    "    min_z, max_z = self._healthy_z_range\n",
    "    is_healthy = jp.where(data.q[2] < min_z, 0.0, 1.0)\n",
    "    is_healthy = jp.where(data.q[2] > max_z, 0.0, is_healthy)\n",
    "    if self._terminate_when_unhealthy:\n",
    "      healthy_reward = self._healthy_reward\n",
    "    else:\n",
    "      healthy_reward = self._healthy_reward * is_healthy\n",
    "\n",
    "    ctrl_cost = self._ctrl_cost_weight * jp.sum(jp.square(action))\n",
    "\n",
    "    obs = self._get_obs(data, action)\n",
    "    reward = forward_reward + healthy_reward - ctrl_cost\n",
    "    done = 1.0 - is_healthy if self._terminate_when_unhealthy else 0.0\n",
    "    state.metrics.update(\n",
    "        forward_reward=forward_reward,\n",
    "        reward_linvel=forward_reward,\n",
    "        reward_quadctrl=-ctrl_cost,\n",
    "        reward_alive=healthy_reward,\n",
    "        x_position=com_after[0],\n",
    "        y_position=com_after[1],\n",
    "        distance_from_origin=jp.linalg.norm(com_after),\n",
    "        x_velocity=velocity[0],\n",
    "        y_velocity=velocity[1],\n",
    "    )\n",
    "\n",
    "    return state.replace(\n",
    "        pipeline_state=data, obs=obs, reward=reward, done=done\n",
    "    )\n",
    "\n",
    "  def _get_obs(\n",
    "      self, data: mjx.Data, action: jp.ndarray\n",
    "  ) -> jp.ndarray:\n",
    "    \"\"\"Observes humanoid body position, velocities, and angles.\"\"\"\n",
    "    position = data.qpos\n",
    "    if self._exclude_current_positions_from_observation:\n",
    "      position = position[2:]\n",
    "\n",
    "    # external_contact_forces are excluded\n",
    "    return jp.concatenate([\n",
    "        position,\n",
    "        data.qvel,\n",
    "        data.cinert[1:].ravel(),\n",
    "        data.cvel[1:].ravel(),\n",
    "        data.qfrc_actuator,\n",
    "    ])\n",
    "\n",
    "\n",
    "envs.register_environment('twoarm', TwoArm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1K6IznI2y83"
   },
   "source": [
    "## Visualize a Rollout\n",
    "\n",
    "Let's instantiate the environment and visualize a short rollout.\n",
    "\n",
    "NOTE: Since episodes terminates early if the torso is below the healthy z-range, the only relevant contacts for this task are between the feet and the plane. We turn off other contacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EhKLFK54C1CH"
   },
   "outputs": [],
   "source": [
    "# instantiate the environment\n",
    "env_name = 'twoarm'\n",
    "env = envs.get_environment(env_name)\n",
    "\n",
    "# define the jit reset/step functions\n",
    "jit_reset = jax.jit(env.reset)\n",
    "jit_step = jax.jit(env.step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ph8u-v2Q2xLS"
   },
   "outputs": [],
   "source": [
    "# initialize the state\n",
    "state = jit_reset(jax.random.PRNGKey(0))\n",
    "rollout = [state.pipeline_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab a trajectory\n",
    "key = jax.random.key(110)\n",
    "for i in range(1000):\n",
    "  ctrl = jax.random.randint(key, 1, 0, env.action_size)\n",
    "  state = jit_step(state, ctrl)\n",
    "  rollout.append(state.pipeline_state)\n",
    "print(\"done\")\n",
    "print(ctrl)\n",
    "print(env.e_list[ctrl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media.show_video(env.render(rollout, camera='top'), fps=1.0 / env.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jax.devices('gpu')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQDG6NQ1CbZD"
   },
   "source": [
    "## Train Two Arm URM Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLiddQYPApBw"
   },
   "outputs": [],
   "source": [
    "train_fn = functools.partial(\n",
    "    ppo.train, num_timesteps=30_000_000, num_evals=5, reward_scaling=0.1,\n",
    "    episode_length=1000, normalize_observations=True, action_repeat=1,\n",
    "    unroll_length=10, num_minibatches=32, num_updates_per_batch=8,\n",
    "    discounting=0.97, learning_rate=3e-4, entropy_cost=1e-3, num_envs=2048,\n",
    "    batch_size=1024, seed=0, discrete_action = True)\n",
    "\n",
    "\n",
    "x_data = []\n",
    "y_data = []\n",
    "ydataerr = []\n",
    "times = [datetime.now()]\n",
    "\n",
    "max_y, min_y = 13000, 0\n",
    "def progress(num_steps, metrics):\n",
    "  times.append(datetime.now())\n",
    "  x_data.append(num_steps)\n",
    "  y_data.append(metrics['eval/episode_reward'])\n",
    "  ydataerr.append(metrics['eval/episode_reward_std'])\n",
    "\n",
    "  plt.xlim([0, train_fn.keywords['num_timesteps'] * 1.25])\n",
    "  plt.ylim([min_y, max_y])\n",
    "\n",
    "  plt.xlabel('# environment steps')\n",
    "  plt.ylabel('reward per episode')\n",
    "  plt.title(f'y={y_data[-1]:.3f}')\n",
    "\n",
    "  plt.errorbar(\n",
    "      x_data, y_data, yerr=ydataerr)\n",
    "  plt.show()\n",
    "\n",
    "make_inference_fn, params, _= train_fn(environment=env, progress_fn=progress)\n",
    "\n",
    "print(f'time to jit: {times[1] - times[0]}')\n",
    "print(f'time to train: {times[-1] - times[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYIch0HEApBx"
   },
   "source": [
    "<!-- ## Save and Load Policy -->\n",
    "\n",
    "We can save and load the policy using the brax model API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z8gI6qH6ApBx"
   },
   "outputs": [],
   "source": [
    "#@title Save Model\n",
    "model_path = '/home/tlee_theaiinstitute_com/mjx_brax_policy/test'\n",
    "model.save_params(model_path, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h4reaWgxApBx"
   },
   "outputs": [],
   "source": [
    "#@title Load Model and Define Inference Function\n",
    "params = model.load_params(model_path)\n",
    "\n",
    "inference_fn = make_inference_fn(params)\n",
    "jit_inference_fn = jax.jit(inference_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0G357XIfApBy"
   },
   "source": [
    "## Visualize Policy\n",
    "\n",
    "Finally we can visualize the policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "osYasMw4ApBy"
   },
   "outputs": [],
   "source": [
    "eval_env = envs.get_environment(env_name)\n",
    "\n",
    "jit_reset = jax.jit(eval_env.reset)\n",
    "jit_step = jax.jit(eval_env.step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d-UhypudApBy"
   },
   "outputs": [],
   "source": [
    "# initialize the state\n",
    "rng = jax.random.PRNGKey(0)\n",
    "state = jit_reset(rng)\n",
    "rollout = [state.pipeline_state]\n",
    "\n",
    "# grab a trajectory\n",
    "n_steps = 500\n",
    "render_every = 2\n",
    "\n",
    "for i in range(n_steps):\n",
    "  act_rng, rng = jax.random.split(rng)\n",
    "  ctrl, _ = jit_inference_fn(state.obs, act_rng)\n",
    "  state = jit_step(state, ctrl)\n",
    "  rollout.append(state.pipeline_state)\n",
    "\n",
    "  if state.done:\n",
    "    break\n",
    "print(\"done\")\n",
    "media.write_video('/home/tlee_theaiinstitute_com/mjx_brax_policy/test.mp4', env.render(rollout[::render_every], camera='side'), fps=1.0 / env.dt / render_every)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zR-heox6LARK"
   },
   "source": [
    "# MJX Policy in MuJoCo\n",
    "\n",
    "We can also perform the physics step using the original MuJoCo python bindings to show that the policy trained in MJX works in MuJoCo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w6ixFi4dApBy"
   },
   "outputs": [],
   "source": [
    "mj_model = eval_env.sys.mj_model\n",
    "mj_data = mujoco.MjData(mj_model)\n",
    "\n",
    "renderer = mujoco.Renderer(mj_model)\n",
    "ctrl = jp.zeros(mj_model.nu)\n",
    "images = []\n",
    "for i in range(n_steps):\n",
    "  act_rng, rng = jax.random.split(rng)\n",
    "\n",
    "  obs = eval_env._get_obs(mjx.put_data(mj_model, mj_data), ctrl)\n",
    "  ctrl, _ = jit_inference_fn(obs, act_rng)\n",
    "  # print(ctrl)\n",
    "  \n",
    "  mj_data.ctrl = ctrl\n",
    "  for _ in range(eval_env._n_frames):\n",
    "    mujoco.mj_step(mj_model, mj_data)  # Physics step using MuJoCo mj_step.\n",
    "  # print(mj_data.qpos)\n",
    "  if i % render_every == 0:\n",
    "    renderer.update_scene(mj_data, camera='side')\n",
    "    images.append(renderer.render())\n",
    "# plt.show(images[100])\n",
    "media.show_video(images) #, fps=1.0 / eval_env.dt / render_every)\n",
    "print(\"done\")\n",
    "# media.write_video('/home/tlee_theaiinstitute_com/mjx_brax_policy/test.mp4', images, fps=1.0 / env.dt / render_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mj_model = eval_env.sys.mj_model\n",
    "mj_data = mujoco.MjData(mj_model)\n",
    "mujoco.mj_step(mj_model, mj_data)\n",
    "renderer.update_scene(mj_data, camera='side')\n",
    "im = renderer.render()\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65mIPj6DQNNa"
   },
   "source": [
    "# Training a Policy with Domain Randomization\n",
    "\n",
    "We might also want to include randomization over certain `mjModel` parameters while training a policy. In MJX, we can easily create a batch of environments with randomized values populated in `mjx.Model`. Below, we show a function that randomizes friction and actuator gain/bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h8mhzKjHQuoL"
   },
   "outputs": [],
   "source": [
    "def domain_randomize(sys, rng):\n",
    "  \"\"\"Randomizes the mjx.Model.\"\"\"\n",
    "  @jax.vmap\n",
    "  def rand(rng):\n",
    "    _, key = jax.random.split(rng, 2)\n",
    "    # friction\n",
    "    friction = jax.random.uniform(key, (1,), minval=0.6, maxval=1.4)\n",
    "    friction = sys.geom_friction.at[:, 0].set(friction)\n",
    "    # actuator\n",
    "    _, key = jax.random.split(key, 2)\n",
    "    gain_range = (-5, 5)\n",
    "    param = jax.random.uniform(\n",
    "        key, (1,), minval=gain_range[0], maxval=gain_range[1]\n",
    "    ) + sys.actuator_gainprm[:, 0]\n",
    "    gain = sys.actuator_gainprm.at[:, 0].set(param)\n",
    "    bias = sys.actuator_biasprm.at[:, 1].set(-param)\n",
    "    return friction, gain, bias\n",
    "\n",
    "  friction, gain, bias = rand(rng)\n",
    "\n",
    "  in_axes = jax.tree_util.tree_map(lambda x: None, sys)\n",
    "  in_axes = in_axes.tree_replace({\n",
    "      'geom_friction': 0,\n",
    "      'actuator_gainprm': 0,\n",
    "      'actuator_biasprm': 0,\n",
    "  })\n",
    "\n",
    "  sys = sys.tree_replace({\n",
    "      'geom_friction': friction,\n",
    "      'actuator_gainprm': gain,\n",
    "      'actuator_biasprm': bias,\n",
    "  })\n",
    "\n",
    "  return sys, in_axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnsZo-GWSYYj"
   },
   "source": [
    "If we wanted 10 environments with randomized friction and actuator params, we can call `domain_randomize`, which returns a batched `mjx.Model` along with a dictionary specifying the axes that are batched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1K45Kp2ASV9s"
   },
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "rng = jax.random.split(rng, 10)\n",
    "batched_sys, _ = domain_randomize(env.sys, rng)\n",
    "\n",
    "print('Single env friction shape: ', env.sys.geom_friction.shape)\n",
    "print('Batched env friction shape: ', batched_sys.geom_friction.shape)\n",
    "\n",
    "print('Friction on geom 0: ', env.sys.geom_friction[0, 0])\n",
    "print('Random frictions on geom 0: ', batched_sys.geom_friction[:, 0, 0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuClass": "premium",
   "gpuType": "V100",
   "machine_shape": "hm",
   "private_outputs": true,
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
